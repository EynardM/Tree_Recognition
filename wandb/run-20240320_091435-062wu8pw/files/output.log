Ultralytics YOLOv8.1.29 üöÄ Python-3.8.10 torch-1.9.0+cu111 CUDA:0 (Tesla T4, 15110MiB)
WARNING ‚ö†Ô∏è Upgrade to torch>=2.0.0 for deterministic training.
[34m[1mengine/trainer: [39m[22mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=400, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=10, cache=False, device=None, workers=8, project=None, name=toto, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/toto
Overriding model.yaml nc=80 with nc=4
                   from  n    params  module                                       arguments
  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]
  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]
  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]
  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]
  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]
  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]
  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]
  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]
  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]
  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']
 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]
 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']
 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]
 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]
 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]
 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]
 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]
 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]
 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]
 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]
 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]
Model summary: 225 layers, 3011628 parameters, 3011612 gradients, 8.2 GFLOPs
Transferred 319/355 items from pretrained weights
/home/eynardmaxime1/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
Freezing layer 'model.22.dfl.conv.weight'
[34m[1mAMP: [39m[22mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...
[34m[1mtrain: [39m[22mScanning /home/eynardmaxime1/Tree_Recognition/Datasets/train/labels.cache... 715 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[34m[1mAMP: [39m[22mchecks passed ‚úÖ
[34m[1mtrain: [39m[22mWARNING ‚ö†Ô∏è /home/eynardmaxime1/Tree_Recognition/Datasets/train/images/B01_0016.JPG: 1 duplicate labels removed
[34m[1mval: [39m[22mScanning /home/eynardmaxime1/Tree_Recognition/Datasets/valid/labels.cache... 88 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|
Plotting labels to runs/detect/toto/labels.jpg...
[34m[1moptimizer:[39m[22m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically...
[34m[1moptimizer:[39m[22m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)
Image sizes 640 train, 640 val
Using 8 dataloader workers
Logging results to [1mruns/detect/toto
Starting training for 400 epochs...
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      1/400      3.58G      2.957      4.169      2.386       2213        640:   4%|‚ñç         | 2/45 [00:03<01:04,  1.51s/it]
Traceback (most recent call last):
  File "train.py", line 35, in <module>
    train_yolov8('n')
  File "train.py", line 24, in train_yolov8
    yolo.train(data='data.yaml', epochs=EPOCHS, batch=BATCH_SIZE,
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/ultralytics/engine/model.py", line 655, in train
    self.trainer.train()
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/ultralytics/engine/trainer.py", line 213, in train
    self._do_train(world_size)
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/ultralytics/engine/trainer.py", line 393, in _do_train
    self.optimizer_step()
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/ultralytics/engine/trainer.py", line 534, in optimizer_step
    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10.0)  # clip gradients
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py", line 42, in clip_grad_norm_
    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py", line 42, in <listcomp>
    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)
KeyboardInterrupt
Traceback (most recent call last):
  File "train.py", line 35, in <module>
    train_yolov8('n')
  File "train.py", line 24, in train_yolov8
    yolo.train(data='data.yaml', epochs=EPOCHS, batch=BATCH_SIZE,
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/ultralytics/engine/model.py", line 655, in train
    self.trainer.train()
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/ultralytics/engine/trainer.py", line 213, in train
    self._do_train(world_size)
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/ultralytics/engine/trainer.py", line 393, in _do_train
    self.optimizer_step()
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/ultralytics/engine/trainer.py", line 534, in optimizer_step
    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10.0)  # clip gradients
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py", line 42, in clip_grad_norm_
    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)
  File "/home/eynardmaxime1/.local/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py", line 42, in <listcomp>
    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)
KeyboardInterrupt